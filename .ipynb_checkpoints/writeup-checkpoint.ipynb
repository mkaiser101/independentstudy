{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Detection: Starbucks Datarobot Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this study a large corpus of tweets were mined using the Twitter timeline api.  The tweets are mainly from the largest coffee chains around the world but also include a few other coorperations such as Aflac and 20th Century Fox.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the tweets were mined, we were left with 16 JSON files per twitter account.  Next, Pandas, a python framework for data handling was used to mapreduce and concatenate the JSON files into one large file per twitter account.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who makes your world a little brighter? #GiveG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@mkuntz0872 Unfortunately we no longer offer s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@nellyann76 It's all yours! You can order it n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@chanelsarianas That sounds amazing! Thanks fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@mikeholliday1 We hope it was just the cozy eg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Who makes your world a little brighter? #GiveG...\n",
       "1  @mkuntz0872 Unfortunately we no longer offer s...\n",
       "2  @nellyann76 It's all yours! You can order it n...\n",
       "3  @chanelsarianas That sounds amazing! Thanks fo...\n",
       "4  @mikeholliday1 We hope it was just the cozy eg..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#Read in 16 datasets of json from Starbucks and Caribou Coffee\n",
    "CC1 = pd.read_json(\"data/cariboucoffee0.json\")\n",
    "CC2 = pd.read_json(\"data/cariboucoffee1.json\")\n",
    "CC3 = pd.read_json(\"data/cariboucoffee2.json\")\n",
    "CC4 = pd.read_json(\"data/cariboucoffee3.json\")\n",
    "CC5 = pd.read_json(\"data/cariboucoffee4.json\")\n",
    "CC6 = pd.read_json(\"data/cariboucoffee5.json\")\n",
    "CC7 = pd.read_json(\"data/cariboucoffee6.json\")\n",
    "CC8 = pd.read_json(\"data/cariboucoffee7.json\")\n",
    "CC9 = pd.read_json(\"data/cariboucoffee8.json\")\n",
    "CC10 = pd.read_json(\"data/cariboucoffee9.json\")\n",
    "CC11 = pd.read_json(\"data/cariboucoffee10.json\")\n",
    "CC12 = pd.read_json(\"data/cariboucoffee11.json\")\n",
    "CC13 = pd.read_json(\"data/cariboucoffee12.json\")\n",
    "CC14 = pd.read_json(\"data/cariboucoffee13.json\")\n",
    "CC15 = pd.read_json(\"data/cariboucoffee14.json\")\n",
    "CC16 = pd.read_json(\"data/cariboucoffee15.json\")\n",
    "CC_map_reduced = pd.concat([CC1,CC2,CC3,CC4,CC5,CC6,CC7,CC8,CC9,CC10,CC11,CC12,CC13,CC14,CC15,CC16], ignore_index=True)\n",
    "CC = CC_map_reduced[[\"text\"]]\n",
    "\n",
    "Sbucks1 = pd.read_json(\"data/Starbucks0.json\")\n",
    "Sbucks2 = pd.read_json(\"data/Starbucks1.json\")\n",
    "Sbucks3 = pd.read_json(\"data/Starbucks2.json\")\n",
    "Sbucks4 = pd.read_json(\"data/Starbucks3.json\")\n",
    "Sbucks5 = pd.read_json(\"data/Starbucks4.json\")\n",
    "Sbucks6 = pd.read_json(\"data/Starbucks5.json\")\n",
    "Sbucks7 = pd.read_json(\"data/Starbucks6.json\")\n",
    "Sbucks8 = pd.read_json(\"data/Starbucks7.json\")\n",
    "Sbucks9 = pd.read_json(\"data/Starbucks8.json\")\n",
    "Sbucks10 = pd.read_json(\"data/Starbucks9.json\")\n",
    "Sbucks11 = pd.read_json(\"data/Starbucks10.json\")\n",
    "Sbucks12 = pd.read_json(\"data/Starbucks11.json\")\n",
    "Sbucks13 = pd.read_json(\"data/Starbucks12.json\")\n",
    "Sbucks14 = pd.read_json(\"data/Starbucks13.json\")\n",
    "Sbucks15 = pd.read_json(\"data/Starbucks14.json\")\n",
    "Sbucks16 = pd.read_json(\"data/Starbucks15.json\")\n",
    "Sbucks_map_reduced = pd.concat([Sbucks1,Sbucks2,Sbucks3,Sbucks4,Sbucks5,Sbucks6,Sbucks7,Sbucks8,Sbucks9,Sbucks10,Sbucks11,Sbucks12,Sbucks13,Sbucks14,Sbucks15,Sbucks16], ignore_index=True)\n",
    "Sbucks = Sbucks_map_reduced[[\"text\"]]\n",
    "Sbucks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the JSONs are organized and tested by brand, we concatenate the brands that are not Starbucks into a Dataframe using Pandas to our class of tweets that will be in the class opposing our Starbucks class:example: anti = pd.concat([DD,Mcds,TH,COCO,CC,bk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anti = CC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we take our two classes being from Starbucks twitter account and NOT from Starbucks twitter account and write the mto a csv file so we can prepare them for the Datarobot api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'starbucks.csv'\n",
    "Sbucks.to_csv(filename, index=False, header=False, encoding='utf-8')\n",
    "\n",
    "filename1 = 'other.csv'\n",
    "anti.to_csv(filename1, index=False, header=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
